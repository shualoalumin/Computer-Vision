{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "문제 1-1. VGG16 모델 구현하기\n",
    "영상의 내용을 참고하여 직접 코드로 모델을 구현해 보세요. Batch Normalization, Parameter Initialization 등을 사용할 수도 있습니다.\n",
    "\n",
    "문제 1-2. 다양한 방법을 사용하여 모델의 성능 올리기\n",
    "skip connection, pre-trained model 등 다양한 방법을 사용하여 기본적인 VGG16 모델의 성능보다 높은 정확도를 구해보세요.\n",
    "\n",
    "먼저 필요한 라이브러리를 불러옵니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "실행 완료\n",
    "데이터를 준비합니다. 불러온 데이터는 캐글에서 제공되는 개와 고양이의 데이터로, 이번 프로젝트에서 우리는 개와 고양이를 분류할 예정입니다. test 데이터에서 1은 개, 0은 고양이를 의미합니다.\n",
    "\n",
    "여러분들이 원하는 이미지 데이터를 불러 Classification을 해보는 것도 좋을 것 같군요. 😊\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "실행 완료\n",
    "train 데이터와 validation 데이터에서 개와 고양이 이미지가 저장된 경로를 각각 변수에 저장해 둡니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234\n",
    "train_dir = os.path.join(path, 'train')\n",
    "validation_dir = os.path.join(path, 'validation')\n",
    "print(train_dir)\n",
    "print(validation_dir)\n",
    "실행 완료\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation\n",
    "\n",
    "\n",
    "\n",
    "123456789101112131415\n",
    "# directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "print(train_cats_dir)\n",
    "\n",
    "# directory with our training dog pictures \n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  \n",
    "print(train_dogs_dir)\n",
    "\n",
    "# directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  \n",
    "\n",
    "실행 완료\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train/dogs\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation/cats\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation/dogs\n",
    "train 데이터와 validation 데이터의 개수를 알아봅시다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789101112131415161718\n",
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "print('total training cat images:', num_cats_tr)\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "print('total validation cat images:', num_cats_val)\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "실행 완료\n",
    "total training cat images: 1000\n",
    "total training dog images: 1000\n",
    "--\n",
    "total validation cat images: 500\n",
    "total validation dog images: 500\n",
    "--\n",
    "Total training images: 2000\n",
    "Total validation images: 1000\n",
    "필요한 파라미터를 설정해 줍시다. 파라미터를 수정하면 성능을 높일 수 있으니 다양한 실험을 해보세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "# parameter Initialization\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "실행 완료\n",
    "이미지를 확인하기 위해 데이터를 시각화하는 함수를 만들어 봅시다. 간단한 함수이기 때문에 자세한 코드 설명은 생략하겠습니다. 궁금하다면 구글링을 통해 각 코드가 어떤 역할을 하는지 찾아보세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789\n",
    "# 데이터를 시각화하기 위한 함수\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "실행 완료\n",
    "train 데이터가 2천장 밖에 되지 않기 때문에 Data Augmentation(데이터 증강)을 통해 데이터의 수를 늘립니다.\n",
    "\n",
    "Data Augmentation은 Rescale, Rotation, Random Crop, Zoom, Flip 등 다양한 기법을 사용하여 데이터의 양을 증가시키는 것입니다. range의 숫자를 변화시키거나 Flip에서 True/False를 적절하게 사용하여 다양한 실험을 해보세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345678\n",
    "# Training data generator\n",
    "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=0.3,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=False)\n",
    "실행 완료\n",
    ".flow_from_directory를 사용하여 파이프라인을 만들어 directory와 작업 환경을 연결시켜 줍니다. 우리는 개와 고양이를 분류하는 task를 수행하기 때문에class_mode는 'binary'입니다. Classification task에 따라 class_mode를 변경하시면 됩니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "실행 완료\n",
    "Found 2000 images belonging to 2 classes.\n",
    "Data Augmentation이 제대로 되었는지 확인해 봅시다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "train_data_gen[0][0].shape\n",
    "실행 완료\n",
    "[40]:\n",
    "(16, 256, 256, 3)\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)\n",
    "실행 완료\n",
    "\n",
    "Validation 데이터에도 train 데이터와 같은 동일한 작업을 해 줍니다. 그러나 Validation 데이터는 classification이 잘 되는지 평가하는 용도로 사용되기 때문에 데이터의 스케일만 변경해 줍니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# Validation data generator\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "실행 완료\n",
    "\n",
    "\n",
    "\n",
    "1234\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='binary')\n",
    "실행 완료\n",
    "Found 1000 images belonging to 2 classes.\n",
    "Validation 데이터를 확인해 봅시다. 크게 이미지와 정답 데이터로 구성이 되어 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "sample_training_images, _ = next(val_data_gen)\n",
    "plotImages(sample_training_images[:5])\n",
    "실행 완료\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "_[:5] # 정답 데이터\n",
    "실행 완료\n",
    "[45]:\n",
    "array([1., 1., 1., 0., 1.], dtype=float32)\n",
    "문제 1-1. VGG16 모델 구현하기\n",
    "이제 VGG16 모델을 구현해 볼 시간입니다. 바로 혼자서 모델을 구현하라고 하면 어렵겠죠? 그래서 참고할만한 모델 구현 코드를 아래에 적어 보았습니다. 실제 VGG16 모델과는 살짝 구조가 다르기 때문에 이미지를 보면서 어느 부분이 다른치 찾아 보는 것도 좋을 것 같습니다.\n",
    "\n",
    "\n",
    "# 참고 코드\n",
    "\n",
    "input_layer=tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "x=tf.keras.layers.Conv2D(32, (3, 3), strides=1, activation='relu', padding='same')(input_layer)\n",
    "x=tf.keras.layers.Conv2D(32, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Flatten()(x)\n",
    "x=tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x=tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "out_layer=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_layer], outputs=[out_layer])\n",
    "model.summary()\n",
    "VGG16 모델의 구조를 다시 상기해 보고, 위의 코드를 참고하여 VGG16 모델을 직접 구현해 보세요.\n",
    "\n",
    "아래 이미지와 동일하게 VGG16 모델을 구현하려면 GPU 크키가 더 커야할 수도 있습니다. 구현한 모델을 학습시키다가 커널이 죽을 경우에는 모델 사이즈를 작게 수정해 보세요.\n",
    "\n",
    "content img\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# 문제1-1. 이미지에 나온 VGG16 모델을 구현하세요.  \n",
    "# [[YOUR CODE]]\n",
    "코드 실행\n",
    "손실함수, optimizer, metric을 설정해 줍니다.\n",
    "\n",
    "손실함수와 metric은 분류 task에 따라 다양하게 바꿀 수 있습니다. optimizer도 Adam 외에 다양한 것을 사용할 수 있습니다. 자유롭게 바꿔보세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789\n",
    "loss_function=tf.keras.losses.binary_crossentropy\n",
    "optimize=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metric=tf.keras.metrics.binary_accuracy\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimize,\n",
    "              metrics=[metric])\n",
    "\n",
    "# callbacks_list= [tf.keras.callbacks.TensorBoard(log_dir='log_dir', histogram_freq=1)]\n",
    "# callback 함수를 활용하고 싶다면 추가해서 학습하는 데에 활용해 보세요.\n",
    "코드 실행\n",
    "모델 학습을 시켜봅시다.\n",
    "data generator는 입력 데이터와 타겟(라벨)의 batch를 끝없이 반환합니다.\n",
    "batch가 끝없이 생성되기 때문에, 한 번의 epoch에 generator로부터 얼마나 많은 샘플을 뽑을지 모델에 전달해야 합니다.\n",
    "만약 batch_size=20이고 steps_per_epoch=100일 경우 (데이터, 라벨)의 쌍 20개가 생성되고, 크기가 20인 batch 데이터를 100번 학습하면 1 epoch이 완료됩니다. 단, 크기 20의 batch 데이터는 매번 랜덤으로 생성됩니다.\n",
    "\n",
    "일반적으로 (전체 데이터 길이/batch_size)를 steps_per_epoch으로 설정합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234567\n",
    "history = model.fit(\n",
    "      train_data_gen,\n",
    "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=val_data_gen,\n",
    "      # callbacks=callbacks_list,\n",
    "      validation_freq=1)\n",
    "코드 실행\n",
    "학습이 되었다면 시각화를 통해 정확도를 알아봅시다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234567891011121314151617181920\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "코드 실행\n",
    "성능이 그리 좋지는 않습니다.\n",
    "\n",
    "문제 1-2. 다양한 방법을 사용하여 모델의 성능 올리기\n",
    "hyperparameter 변경, 모델 수정, optimizer 변경, skip connection, pre-trained model 등 다양한 방법을 사용하면 모델의 성능을 높일 수 있습니다. 다양한 실험을 통해 성능을 올려 보세요.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# 문제 1-2. hyperparameter 설정\n",
    "# [[YOUR CODE]]\n",
    "코드 실행\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# 문제 1-2. 데이터 generator 생성\n",
    "# [[YOUR CODE]]\n",
    "코드 실행\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# 문제 1-2. 모델 구현\n",
    "# [[YOUR CODE]]\n",
    "코드 실행\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# 문제 1-2. loss function, optimizer, metric 설정 및 모델 컴파일\n",
    "# [[YOUR CODE]]\n",
    "코드 실행\n",
    "\n",
    "\n",
    "\n",
    "12345678\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "      train_data_gen,\n",
    "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=val_data_gen,\n",
    "      # callbacks=callbacks_list,\n",
    "      validation_freq=1)\n",
    "코드 실행\n",
    "\n",
    "\n",
    "\n",
    "1234567891011121314151617181920\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
