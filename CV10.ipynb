{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ë¬¸ì œ 1-1. VGG16 ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n",
    "ì˜ìƒì˜ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì½”ë“œë¡œ ëª¨ë¸ì„ êµ¬í˜„í•´ ë³´ì„¸ìš”. Batch Normalization, Parameter Initialization ë“±ì„ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¬¸ì œ 1-2. ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ ì˜¬ë¦¬ê¸°\n",
    "skip connection, pre-trained model ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ì ì¸ VGG16 ëª¨ë¸ì˜ ì„±ëŠ¥ë³´ë‹¤ ë†’ì€ ì •í™•ë„ë¥¼ êµ¬í•´ë³´ì„¸ìš”.\n",
    "\n",
    "ë¨¼ì € í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤. ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ëŠ” ìºê¸€ì—ì„œ ì œê³µë˜ëŠ” ê°œì™€ ê³ ì–‘ì´ì˜ ë°ì´í„°ë¡œ, ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ìš°ë¦¬ëŠ” ê°œì™€ ê³ ì–‘ì´ë¥¼ ë¶„ë¥˜í•  ì˜ˆì •ì…ë‹ˆë‹¤. test ë°ì´í„°ì—ì„œ 1ì€ ê°œ, 0ì€ ê³ ì–‘ì´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ëŸ¬ë¶„ë“¤ì´ ì›í•˜ëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ Classificationì„ í•´ë³´ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™êµ°ìš”. ğŸ˜Š\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "train ë°ì´í„°ì™€ validation ë°ì´í„°ì—ì„œ ê°œì™€ ê³ ì–‘ì´ ì´ë¯¸ì§€ê°€ ì €ì¥ëœ ê²½ë¡œë¥¼ ê°ê° ë³€ìˆ˜ì— ì €ì¥í•´ ë‘¡ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234\n",
    "train_dir = os.path.join(path, 'train')\n",
    "validation_dir = os.path.join(path, 'validation')\n",
    "print(train_dir)\n",
    "print(validation_dir)\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation\n",
    "\n",
    "\n",
    "\n",
    "123456789101112131415\n",
    "# directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') \n",
    "print(train_cats_dir)\n",
    "\n",
    "# directory with our training dog pictures \n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  \n",
    "print(train_dogs_dir)\n",
    "\n",
    "# directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  \n",
    "\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/train/dogs\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation/cats\n",
    "/aiffel/.keras/datasets/cats_and_dogs_filtered/validation/dogs\n",
    "train ë°ì´í„°ì™€ validation ë°ì´í„°ì˜ ê°œìˆ˜ë¥¼ ì•Œì•„ë´…ì‹œë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789101112131415161718\n",
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "print('total training cat images:', num_cats_tr)\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "\n",
    "print(\"--\")\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "print('total validation cat images:', num_cats_val)\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "total training cat images: 1000\n",
    "total training dog images: 1000\n",
    "--\n",
    "total validation cat images: 500\n",
    "total validation dog images: 500\n",
    "--\n",
    "Total training images: 2000\n",
    "Total validation images: 1000\n",
    "í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•´ ì¤ì‹œë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ë©´ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í•´ë³´ì„¸ìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "# parameter Initialization\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "ì´ë¯¸ì§€ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ ë´…ì‹œë‹¤. ê°„ë‹¨í•œ í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— ìì„¸í•œ ì½”ë“œ ì„¤ëª…ì€ ìƒëµí•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ë‹¤ë©´ êµ¬ê¸€ë§ì„ í†µí•´ ê° ì½”ë“œê°€ ì–´ë–¤ ì—­í• ì„ í•˜ëŠ”ì§€ ì°¾ì•„ë³´ì„¸ìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789\n",
    "# ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ê¸° ìœ„í•œ í•¨ìˆ˜\n",
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "train ë°ì´í„°ê°€ 2ì²œì¥ ë°–ì— ë˜ì§€ ì•Šê¸° ë•Œë¬¸ì— Data Augmentation(ë°ì´í„° ì¦ê°•)ì„ í†µí•´ ë°ì´í„°ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.\n",
    "\n",
    "Data Augmentationì€ Rescale, Rotation, Random Crop, Zoom, Flip ë“± ë‹¤ì–‘í•œ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì˜ ì–‘ì„ ì¦ê°€ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤. rangeì˜ ìˆ«ìë¥¼ ë³€í™”ì‹œí‚¤ê±°ë‚˜ Flipì—ì„œ True/Falseë¥¼ ì ì ˆí•˜ê²Œ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í•´ë³´ì„¸ìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345678\n",
    "# Training data generator\n",
    "image_gen_train = ImageDataGenerator(rescale=1./255,\n",
    "                                     rotation_range=0.3,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True, \n",
    "                                     vertical_flip=False)\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    ".flow_from_directoryë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ì–´ directoryì™€ ì‘ì—… í™˜ê²½ì„ ì—°ê²°ì‹œì¼œ ì¤ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê°œì™€ ê³ ì–‘ì´ë¥¼ ë¶„ë¥˜í•˜ëŠ” taskë¥¼ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì—class_modeëŠ” 'binary'ì…ë‹ˆë‹¤. Classification taskì— ë”°ë¼ class_modeë¥¼ ë³€ê²½í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12345\n",
    "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "Found 2000 images belonging to 2 classes.\n",
    "Data Augmentationì´ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "train_data_gen[0][0].shape\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "[40]:\n",
    "(16, 256, 256, 3)\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
    "plotImages(augmented_images)\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "\n",
    "Validation ë°ì´í„°ì—ë„ train ë°ì´í„°ì™€ ê°™ì€ ë™ì¼í•œ ì‘ì—…ì„ í•´ ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Validation ë°ì´í„°ëŠ” classificationì´ ì˜ ë˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ë˜ê¸° ë•Œë¬¸ì— ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ë§Œ ë³€ê²½í•´ ì¤ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# Validation data generator\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "\n",
    "\n",
    "\n",
    "1234\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory=validation_dir,\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='binary')\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "Found 1000 images belonging to 2 classes.\n",
    "Validation ë°ì´í„°ë¥¼ í™•ì¸í•´ ë´…ì‹œë‹¤. í¬ê²Œ ì´ë¯¸ì§€ì™€ ì •ë‹µ ë°ì´í„°ë¡œ êµ¬ì„±ì´ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "sample_training_images, _ = next(val_data_gen)\n",
    "plotImages(sample_training_images[:5])\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "_[:5] # ì •ë‹µ ë°ì´í„°\n",
    "ì‹¤í–‰ ì™„ë£Œ\n",
    "[45]:\n",
    "array([1., 1., 1., 0., 1.], dtype=float32)\n",
    "ë¬¸ì œ 1-1. VGG16 ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n",
    "ì´ì œ VGG16 ëª¨ë¸ì„ êµ¬í˜„í•´ ë³¼ ì‹œê°„ì…ë‹ˆë‹¤. ë°”ë¡œ í˜¼ìì„œ ëª¨ë¸ì„ êµ¬í˜„í•˜ë¼ê³  í•˜ë©´ ì–´ë µê² ì£ ? ê·¸ë˜ì„œ ì°¸ê³ í• ë§Œí•œ ëª¨ë¸ êµ¬í˜„ ì½”ë“œë¥¼ ì•„ë˜ì— ì ì–´ ë³´ì•˜ìŠµë‹ˆë‹¤. ì‹¤ì œ VGG16 ëª¨ë¸ê³¼ëŠ” ì‚´ì§ êµ¬ì¡°ê°€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ë¥¼ ë³´ë©´ì„œ ì–´ëŠ ë¶€ë¶„ì´ ë‹¤ë¥¸ì¹˜ ì°¾ì•„ ë³´ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "# ì°¸ê³  ì½”ë“œ\n",
    "\n",
    "input_layer=tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "x=tf.keras.layers.Conv2D(32, (3, 3), strides=1, activation='relu', padding='same')(input_layer)\n",
    "x=tf.keras.layers.Conv2D(32, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.Conv2D(128, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x=tf.keras.layers.BatchNormalization()(x)\n",
    "x=tf.keras.layers.MaxPool2D((2, 2))(x)\n",
    "\n",
    "x=tf.keras.layers.Flatten()(x)\n",
    "x=tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x=tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "out_layer=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_layer], outputs=[out_layer])\n",
    "model.summary()\n",
    "VGG16 ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ìƒê¸°í•´ ë³´ê³ , ìœ„ì˜ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ VGG16 ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "ì•„ë˜ ì´ë¯¸ì§€ì™€ ë™ì¼í•˜ê²Œ VGG16 ëª¨ë¸ì„ êµ¬í˜„í•˜ë ¤ë©´ GPU í¬í‚¤ê°€ ë” ì»¤ì•¼í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. êµ¬í˜„í•œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ë‹¤ê°€ ì»¤ë„ì´ ì£½ì„ ê²½ìš°ì—ëŠ” ëª¨ë¸ ì‚¬ì´ì¦ˆë¥¼ ì‘ê²Œ ìˆ˜ì •í•´ ë³´ì„¸ìš”.\n",
    "\n",
    "content img\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# ë¬¸ì œ1-1. ì´ë¯¸ì§€ì— ë‚˜ì˜¨ VGG16 ëª¨ë¸ì„ êµ¬í˜„í•˜ì„¸ìš”.  \n",
    "# [[YOUR CODE]]\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "ì†ì‹¤í•¨ìˆ˜, optimizer, metricì„ ì„¤ì •í•´ ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ì†ì‹¤í•¨ìˆ˜ì™€ metricì€ ë¶„ë¥˜ taskì— ë”°ë¼ ë‹¤ì–‘í•˜ê²Œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤. optimizerë„ Adam ì™¸ì— ë‹¤ì–‘í•œ ê²ƒì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ììœ ë¡­ê²Œ ë°”ê¿”ë³´ì„¸ìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "123456789\n",
    "loss_function=tf.keras.losses.binary_crossentropy\n",
    "optimize=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metric=tf.keras.metrics.binary_accuracy\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimize,\n",
    "              metrics=[metric])\n",
    "\n",
    "# callbacks_list= [tf.keras.callbacks.TensorBoard(log_dir='log_dir', histogram_freq=1)]\n",
    "# callback í•¨ìˆ˜ë¥¼ í™œìš©í•˜ê³  ì‹¶ë‹¤ë©´ ì¶”ê°€í•´ì„œ í•™ìŠµí•˜ëŠ” ë°ì— í™œìš©í•´ ë³´ì„¸ìš”.\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "ëª¨ë¸ í•™ìŠµì„ ì‹œì¼œë´…ì‹œë‹¤.\n",
    "data generatorëŠ” ì…ë ¥ ë°ì´í„°ì™€ íƒ€ê²Ÿ(ë¼ë²¨)ì˜ batchë¥¼ ëì—†ì´ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "batchê°€ ëì—†ì´ ìƒì„±ë˜ê¸° ë•Œë¬¸ì—, í•œ ë²ˆì˜ epochì— generatorë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë§ì€ ìƒ˜í”Œì„ ë½‘ì„ì§€ ëª¨ë¸ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ë§Œì•½ batch_size=20ì´ê³  steps_per_epoch=100ì¼ ê²½ìš° (ë°ì´í„°, ë¼ë²¨)ì˜ ìŒ 20ê°œê°€ ìƒì„±ë˜ê³ , í¬ê¸°ê°€ 20ì¸ batch ë°ì´í„°ë¥¼ 100ë²ˆ í•™ìŠµí•˜ë©´ 1 epochì´ ì™„ë£Œë©ë‹ˆë‹¤. ë‹¨, í¬ê¸° 20ì˜ batch ë°ì´í„°ëŠ” ë§¤ë²ˆ ëœë¤ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì¼ë°˜ì ìœ¼ë¡œ (ì „ì²´ ë°ì´í„° ê¸¸ì´/batch_size)ë¥¼ steps_per_epochìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234567\n",
    "history = model.fit(\n",
    "      train_data_gen,\n",
    "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=val_data_gen,\n",
    "      # callbacks=callbacks_list,\n",
    "      validation_freq=1)\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "í•™ìŠµì´ ë˜ì—ˆë‹¤ë©´ ì‹œê°í™”ë¥¼ í†µí•´ ì •í™•ë„ë¥¼ ì•Œì•„ë´…ì‹œë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1234567891011121314151617181920\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "ì„±ëŠ¥ì´ ê·¸ë¦¬ ì¢‹ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë¬¸ì œ 1-2. ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ ì˜¬ë¦¬ê¸°\n",
    "hyperparameter ë³€ê²½, ëª¨ë¸ ìˆ˜ì •, optimizer ë³€ê²½, skip connection, pre-trained model ë“± ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í†µí•´ ì„±ëŠ¥ì„ ì˜¬ë ¤ ë³´ì„¸ìš”.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# ë¬¸ì œ 1-2. hyperparameter ì„¤ì •\n",
    "# [[YOUR CODE]]\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# ë¬¸ì œ 1-2. ë°ì´í„° generator ìƒì„±\n",
    "# [[YOUR CODE]]\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# ë¬¸ì œ 1-2. ëª¨ë¸ êµ¬í˜„\n",
    "# [[YOUR CODE]]\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    "12\n",
    "# ë¬¸ì œ 1-2. loss function, optimizer, metric ì„¤ì • ë° ëª¨ë¸ ì»´íŒŒì¼\n",
    "# [[YOUR CODE]]\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    "12345678\n",
    "# ëª¨ë¸ í•™ìŠµ\n",
    "history = model.fit(\n",
    "      train_data_gen,\n",
    "      steps_per_epoch=(len(os.listdir(train_cats_dir)) + len(os.listdir(train_dogs_dir)))/batch_size,\n",
    "      epochs=epochs,\n",
    "      validation_data=val_data_gen,\n",
    "      # callbacks=callbacks_list,\n",
    "      validation_freq=1)\n",
    "ì½”ë“œ ì‹¤í–‰\n",
    "\n",
    "\n",
    "\n",
    "1234567891011121314151617181920\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.plot(epochs_range, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs_range, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
